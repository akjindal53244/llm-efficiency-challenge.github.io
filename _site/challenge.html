<!DOCTYPE html>
<html lang=" en-US">

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    
    <meta charset="UTF-8">

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>NeurIPS Large Language Model Efficiency Challenge:1 LLM + 1GPU + 1Day | NeurIPS 2023 Challenge</title>
<meta name="generator" content="Jekyll v3.9.3">
<meta property="og:title" content="NeurIPS Large Language Model Efficiency Challenge:1 LLM + 1GPU + 1Day">
<meta property="og:locale" content="en_US">
<meta name="description" content="NeurIPS 2023 Challenge">
<meta property="og:description" content="NeurIPS 2023 Challenge">
<link rel="canonical" href="http://localhost:4000/challenge.html">
<meta property="og:url" content="http://localhost:4000/challenge.html">
<meta property="og:site_name" content="NeurIPS Large Language Model Efficiency Challenge:1 LLM + 1GPU + 1Day">
<meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="NeurIPS Large Language Model Efficiency Challenge:1 LLM + 1GPU + 1Day">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"NeurIPS 2023 Challenge","headline":"NeurIPS Large Language Model Efficiency Challenge:1 LLM + 1GPU + 1Day","url":"http://localhost:4000/challenge.html"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&amp;display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  
    <!-- KaTeX -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous">

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx" crossorigin="anonymous"></script>

    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>

    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <style type="text/css">
        /* Style the tab */
        .tab {
            overflow: hidden;
            border: 1px solid #ccc;
            background-color: #fdfdff;
        }

        /* Style the buttons that are used to open the tab content */
        .tab button {
            background-color: inherit;
            float: left;
            border: none;
            outline: none;
            cursor: pointer;
            padding: 14px 16px;
            transition: 0.3s;
        }

        /* Change background color of buttons on hover */
        .tab button:hover {
            background-color: #ddd;
        }

        /* Create an active/current tablink class */
        .tab button.active {
            background-color: #ccc;
        }

        /* Style the tab content */
        .tabcontent {
            display: none;
            padding: 6px 12px;
            border: 1px solid #ccc;
            border-top: none;
        }
    </style>


<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <header class="page-header" role="banner">
        <h1 class="project-name">NeurIPS Large Language Model Efficiency Challenge:<br>1 LLM + 1GPU + 1Day</h1>
        <h2 class="project-tagline">NeurIPS 2023 Challenge</h2>
        
        <a href="index" class="btn">Home</a>
        
        <a href="challenge" class="btn">Challenge</a>
        
        <a href="rules" class="btn">Rules</a>
        
        <a href="dates" class="btn">Timeline</a>
        
        <a href="prizes" class="btn">Prizes</a>
        
        <a href="starter_kit" class="btn">Starter Kit</a>
        
        <a href="leaderboard" class="btn">Leaderboard</a>
        
        <a href="organizers" class="btn">Organizers</a>
        
        <a href="advisors" class="btn">Advisors</a>
        
        <a href="sponsors" class="btn">Sponsors</a>
        
        <a href="question" class="btn">Contact Us</a>
        

    </header>

    <main id="content" class="main-content" role="main">
        <p style="text-align: justify;">

To participate in this competition, you must start with a base model from our approved list, utilize only open-source data, and limit your fine-tuning to a single <strong>24-hour</strong> period. This fine-tuning should be carried out on just one graphics card, which must be either the <strong>NVIDIA 4090</strong> or the <strong>NVIDIA A100</strong>.
Our competition will feature two hardware tracks: the <strong>NVIDIA 4090 track</strong>  and  the <strong>NVIDIA A100 track</strong>, and each track will be evaluated separately.

</p>

<h2 id="approved-base-models">Approved Base models:</h2>

<p style="text-align: justify;">
The starting model for the competition should be an open <a href="https://spdx.org/licenses/MIT.html">MIT</a> or <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache 2</a>) base model without instruction-tuning. All sizes of the common autoregressive and autoencoder base models listed below are allowed. 

</p>

<ul>
  <li>Falcon</li>
  <li>LLaMA</li>
  <li>OpenLLaMA</li>
  <li>Red Pajama Base (not instruction tuned models)</li>
  <li>MPT</li>
  <li>OPT</li>
  <li>Bloom</li>
  <li>GPT Neo, J, NeoX, Pythia</li>
  <li>GPT2</li>
  <li>T5 (not Flan-T5)</li>
  <li>BART</li>
  <li>DeBERTa</li>
  <li>RoBERTa</li>
  <li>BERT</li>
  <li>ALBERT</li>
  <li>DistilBERT</li>
  <li>Electra</li>
</ul>

<p><br></p>

<p>If you plan to use an open-source base model family not listed here, please reach out to us and we will consider adding it to the list. Please respect the honor system in place for this competition, and acquire your base model through legitimate channels only. (i.e. No pirated LLaMA weights). Any submissions that use base models obtained through illicit means will be disqualified.</p>

<h2 id="datasets">Datasets:</h2>

<p style="text-align: justify;">
You are welcome to use any open sourced dataset. For example:
</p>

<ul>
  <li><a href="https://huggingface.co/datasets/databricks/databricks-dolly-15k">Databricks-Dolly-15</a></li>
  <li><a href="https://huggingface.co/datasets/OpenAssistant/oasst1">OpenAssistant Conversations Dataset (oasst1)</a></li>
  <li><a href="https://github.com/mobarski/alpaca-libre">Alpaca Libre</a></li>
</ul>

<p><br></p>

<p style="text-align: justify;">
Under no circumstances should you use data that infringes upon data usage agreements, copyright laws, or privacy policies. This means you should not use datasets that utilize generated content, whether in the form of instructions/prompts or results/answers from another LLM. If you opt to create your own dataset, it must be open-sourced and readily accessible to the general public at the time of submission.
</p>

<p><br></p>

<h2 id="evaluation">Evaluation:</h2>

<p style="text-align: justify;">

The evaluation process in our competition will be conducted in two stages. In the first stage, we will run a subset of HELM benchmark along with a set of secret holdout tasks. The holdout tasks will consist of logic reasoning type of multiple-choice Q&amp;A scenarios as well as conversational chat tasks. Submissions will be ranked based on their performance across all tasks. The ranking will be determined by the geometric mean across all evaluation tasks. This score will be shown in the leaderboard 

<br><br>

$$\text{score} = \Pi ( \text{mean-win-rate(\text{task})} )$$

<br>

After the competition is closed on September 30th 2023, we will contact the top 3 teams with the highest scoring models in each hardware category, requesting that they submit all necessary code and data to reproduce their model, starting from their chosen open-source base model. We will then replicate their entire process, to ensure it is repeatable and same results can be achieved with 24 hours using a single GPU. If the top-scoring model cannot be reproduced under these imposed conditions, we will move on to consider the next highest-scoring model in the hardware category, we will continue this process until a reproducible and high-performing model is selected, or we exhaust all potential options and declare no winners for the category.

</p>


        <footer class="site-footer">
            <hr>
            <!-- 
            <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub
                    Pages</a>.</span> -->
        </footer>
    </main>

</body>

</html>
